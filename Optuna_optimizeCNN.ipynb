{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Optuna-optimizeCNN.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/mahesh-ml/MLBasics/blob/main/Optuna_optimizeCNN.ipynb",
      "authorship_tag": "ABX9TyNFVdz7LBUsCZOYxhcF9M8+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahesh-ml/MLBasics/blob/main/Optuna_optimizeCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8WnVvOtc_cm"
      },
      "source": [
        "import os\n",
        "os.environ['PYTHONHASHSEED'] = '0'\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random as python_random\n",
        "\n",
        "np.random.seed(123)\n",
        "python_random.seed(123)\n",
        "\n",
        "tf.random.set_seed(1234)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EocOLKu8fQz9",
        "outputId": "3176e0b0-8c07-4a70-cf18-5c43ad650650"
      },
      "source": [
        "!pip install optuna\n",
        "import optuna"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.7/dist-packages (2.10.0)\n",
            "Requirement already satisfied: cliff in /usr/local/lib/python3.7/dist-packages (from optuna) (3.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.19.5)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.7/dist-packages (from optuna) (6.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.62.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.7/dist-packages (from optuna) (1.7.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.2)\n",
            "Requirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from optuna) (0.8.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.26)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (2.4.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.8.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.4.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (1.1.5)\n",
            "Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.2.0)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (5.7.0)\n",
            "Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.5.0)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.4.0)\n",
            "Requirement already satisfied: autopage>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (0.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (3.10.0.2)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.2.0)\n",
            "Requirement already satisfied: colorama>=0.3.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.4.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXpmcCZAdsRO"
      },
      "source": [
        "import itertools\n",
        "from functools import partial\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense,Flatten,Conv2D , MaxPool2D\n",
        "from tensorflow.keras.optimizers import Adam,RMSprop\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snClXSttfYNV"
      },
      "source": [
        "data = pd.read_csv(\"/content/mnist.csv\")"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "1fmbR5mQfnaA",
        "outputId": "d2476202-8dcd-439f-8467-039579ada9d1"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel744</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  pixel0  pixel1  pixel2  ...  pixel780  pixel781  pixel782  pixel783\n",
              "0      1       0       0       0  ...         0         0         0         0\n",
              "1      0       0       0       0  ...         0         0         0         0\n",
              "2      1       0       0       0  ...         0         0         0         0\n",
              "3      4       0       0       0  ...         0         0         0         0\n",
              "4      0       0       0       0  ...         0         0         0         0\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQjDiJLThBqM",
        "outputId": "18e5e379-7dc6-4abf-d48b-cb55c03b4292"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['label'],axis=1),data['label'],test_size=0.1, random_state=0)\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((37800, 784), (4200, 784))"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3uASx2Wz6Md",
        "outputId": "05a39d77-e4ba-429a-b94f-ce3334550868",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "g = sns.countplot(x=y_train)\n",
        "plt.xlabel(\"digits\")\n",
        "plt.ylabel('number of images')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'number of images')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLx5ORLC0NIP"
      },
      "source": [
        "#rescale and reshape\n",
        "X_train= X_train / 255\n",
        "X_test = X_test /255\n",
        "\n",
        "#reshape\n",
        "X_train=X_train.values.reshape(-1,28,28,1)\n",
        "X_test=X_test.values.reshape(-1,28,28,1)\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUa3rMnylfh8",
        "outputId": "54766561-2b1c-4d10-85d3-da084f9a86b0"
      },
      "source": [
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "\n",
        "y_train"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk7AX6tBlWQR"
      },
      "source": [
        "path_best_model='cnn_model.h5'\n",
        "best_accuracy=0"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ6lkbHYmliv"
      },
      "source": [
        "#objective function\n",
        "def objective(trial):\n",
        "  model= Sequential()\n",
        "  num_conv_layers= trial.suggest_int('num_conv_layers',1,3)\n",
        "\n",
        "  for i in range(num_conv_layers):\n",
        "    model.add(Conv2D(\n",
        "                     filters=trial.suggest_categorical('filters',[16,32,64]),\n",
        "                     kernel_size=trial.suggest_categorical('kernel_size',[3,5]),\n",
        "                     strides=trial.suggest_categorical('strides',[1,2]),\n",
        "                     activation= trial.suggest_categorical('activation',['relu','tanh']), padding='same'\n",
        "              \n",
        "              ))\n",
        "    model.add(MaxPool2D(pool_size=2, strides=2))\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    num_dense_layers = trial.suggest_int('num_dense_layers', 1, 3)\n",
        "\n",
        "    for i in range(num_dense_layers):\n",
        "        model.add(Dense(\n",
        "             units = trial.suggest_int('units', 5,512),\n",
        "             activation = trial.suggest_categorical('activation',['relu','tanh'])\n",
        "        ))\n",
        "    model.add(Dense(10,activation='softmax'))\n",
        "\n",
        "    optimizer_name = trial.suggest_categorical('optimizer_name',['Adam','RMRProp'])\n",
        "\n",
        "    if optimizer_name == 'Adam':\n",
        "       optimizer = Adam(lr=trial.suggest_float('learning_rate',1e-6, 1e-2))\n",
        "    else:\n",
        "       optimizer = RMSprop(lr=trial.suggest_float('learning_rate',1e-6, 1e-2), \n",
        "                           momentum = trial.suggest_float('momentum',0.1,0.9))\n",
        "       \n",
        "    #compile model\n",
        "  \n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    #train model\n",
        "    history = model.fit(x=X_train, \n",
        "                        y = y_train, \n",
        "                        epochs=3, \n",
        "                        batch_size=128,\n",
        "                        validation_split=0.1)\n",
        "\n",
        "    #accuracy\n",
        "    accuracy= history.history['val_accuracy'][-1]\n",
        "\n",
        "    global best_accuracy\n",
        "\n",
        "    if accuracy > best_accuracy:\n",
        "        model.save(path_best_model)\n",
        "        best_accuracy = accuracy\n",
        "\n",
        "    del model\n",
        "\n",
        "    return accuracy"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFi0eA83sN6c"
      },
      "source": [
        "study_name='cnn_study'\n",
        "storage_name=\"sqlite:///{}.db\".format(study_name)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KxtnLG1sc7i",
        "outputId": "a85083d5-bbe8-4251-a4f3-ce674c88aeaa"
      },
      "source": [
        "study = optuna.create_study(\n",
        "    direction='maximize',\n",
        "    study_name=study_name,\n",
        "    storage= storage_name,\n",
        "    load_if_exists=True\n",
        "\n",
        ")\n",
        "\n",
        "study.optimize(objective, n_trials=30)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-11-10 22:06:18,127]\u001b[0m Using an existing study with name 'cnn_study' instead of creating a new one.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "266/266 [==============================] - 4s 13ms/step - loss: 1.1996 - accuracy: 0.6572 - val_loss: 0.2282 - val_accuracy: 0.9304\n",
            "Epoch 2/3\n",
            "266/266 [==============================] - 3s 11ms/step - loss: 0.1776 - accuracy: 0.9491 - val_loss: 0.2085 - val_accuracy: 0.9426\n",
            "Epoch 3/3\n",
            "266/266 [==============================] - 3s 11ms/step - loss: 0.1245 - accuracy: 0.9647 - val_loss: 0.2172 - val_accuracy: 0.9481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-11-10 22:06:31,124]\u001b[0m Trial 30 finished with value: 0.9481481313705444 and parameters: {'num_conv_layers': 1, 'filters': 32, 'kernel_size': 5, 'strides': 1, 'activation': 'tanh', 'num_dense_layers': 2, 'units': 506, 'optimizer_name': 'RMRProp', 'learning_rate': 0.002769725063768323, 'momentum': 0.5524715000083009}. Best is trial 30 with value: 0.9481481313705444.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 0.7160 - accuracy: 0.8164 - val_loss: 0.3389 - val_accuracy: 0.9053\n",
            "Epoch 2/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.2633 - accuracy: 0.9303 - val_loss: 0.2405 - val_accuracy: 0.9347\n",
            "Epoch 3/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.2070 - accuracy: 0.9438 - val_loss: 0.2198 - val_accuracy: 0.9405\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-11-10 22:06:37,205]\u001b[0m Trial 31 finished with value: 0.9404761791229248 and parameters: {'num_conv_layers': 1, 'filters': 32, 'kernel_size': 3, 'strides': 2, 'activation': 'tanh', 'num_dense_layers': 2, 'units': 6, 'optimizer_name': 'RMRProp', 'learning_rate': 0.0029109256056534367, 'momentum': 0.5694703261605986}. Best is trial 30 with value: 0.9481481313705444.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "266/266 [==============================] - 3s 8ms/step - loss: 0.3542 - accuracy: 0.8992 - val_loss: 0.2388 - val_accuracy: 0.9312\n",
            "Epoch 2/3\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 0.1473 - accuracy: 0.9563 - val_loss: 0.1541 - val_accuracy: 0.9553\n",
            "Epoch 3/3\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 0.1178 - accuracy: 0.9654 - val_loss: 0.1468 - val_accuracy: 0.9624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-11-10 22:06:44,085]\u001b[0m Trial 32 finished with value: 0.9624338746070862 and parameters: {'num_conv_layers': 1, 'filters': 16, 'kernel_size': 3, 'strides': 2, 'activation': 'tanh', 'num_dense_layers': 2, 'units': 483, 'optimizer_name': 'RMRProp', 'learning_rate': 0.002831168767480192, 'momentum': 0.517012269177247}. Best is trial 32 with value: 0.9624338746070862.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 0.2570 - accuracy: 0.9203 - val_loss: 0.1390 - val_accuracy: 0.9556\n",
            "Epoch 2/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.1235 - accuracy: 0.9630 - val_loss: 0.1496 - val_accuracy: 0.9598\n",
            "Epoch 3/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.0924 - accuracy: 0.9721 - val_loss: 0.1342 - val_accuracy: 0.9643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-11-10 22:06:50,256]\u001b[0m Trial 33 finished with value: 0.9642857313156128 and parameters: {'num_conv_layers': 1, 'filters': 16, 'kernel_size': 3, 'strides': 2, 'activation': 'tanh', 'num_dense_layers': 2, 'units': 267, 'optimizer_name': 'RMRProp', 'learning_rate': 0.0026660584335518617, 'momentum': 0.5620485699269737}. Best is trial 33 with value: 0.9642857313156128.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 0.2701 - accuracy: 0.9194 - val_loss: 0.1364 - val_accuracy: 0.9614\n",
            "Epoch 2/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.1034 - accuracy: 0.9684 - val_loss: 0.1144 - val_accuracy: 0.9659\n",
            "Epoch 3/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.0742 - accuracy: 0.9765 - val_loss: 0.1128 - val_accuracy: 0.9696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-11-10 22:06:56,421]\u001b[0m Trial 34 finished with value: 0.9695767164230347 and parameters: {'num_conv_layers': 1, 'filters': 16, 'kernel_size': 3, 'strides': 2, 'activation': 'tanh', 'num_dense_layers': 2, 'units': 33, 'optimizer_name': 'RMRProp', 'learning_rate': 0.002790374237886413, 'momentum': 0.5534952567846437}. Best is trial 34 with value: 0.9695767164230347.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.2503 - accuracy: 0.9215 - val_loss: 0.1536 - val_accuracy: 0.9529\n",
            "Epoch 2/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.1101 - accuracy: 0.9665 - val_loss: 0.1197 - val_accuracy: 0.9669\n",
            "Epoch 3/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.0775 - accuracy: 0.9752 - val_loss: 0.1234 - val_accuracy: 0.9643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-11-10 22:07:02,508]\u001b[0m Trial 35 finished with value: 0.9642857313156128 and parameters: {'num_conv_layers': 1, 'filters': 16, 'kernel_size': 3, 'strides': 2, 'activation': 'tanh', 'num_dense_layers': 2, 'units': 107, 'optimizer_name': 'RMRProp', 'learning_rate': 0.0028475382572120105, 'momentum': 0.5042083370338958}. Best is trial 34 with value: 0.9695767164230347.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.2713 - accuracy: 0.9166 - val_loss: 0.1415 - val_accuracy: 0.9574\n",
            "Epoch 2/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.1041 - accuracy: 0.9681 - val_loss: 0.1215 - val_accuracy: 0.9664\n",
            "Epoch 3/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.0740 - accuracy: 0.9772 - val_loss: 0.0891 - val_accuracy: 0.9741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-11-10 22:07:08,402]\u001b[0m Trial 36 finished with value: 0.9740740656852722 and parameters: {'num_conv_layers': 1, 'filters': 16, 'kernel_size': 3, 'strides': 2, 'activation': 'tanh', 'num_dense_layers': 2, 'units': 42, 'optimizer_name': 'RMRProp', 'learning_rate': 0.002878983904416791, 'momentum': 0.4781051050947992}. Best is trial 36 with value: 0.9740740656852722.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 0.2779 - accuracy: 0.9143 - val_loss: 0.1372 - val_accuracy: 0.9595\n",
            "Epoch 2/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.1093 - accuracy: 0.9670 - val_loss: 0.1414 - val_accuracy: 0.9587\n",
            "Epoch 3/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.0782 - accuracy: 0.9749 - val_loss: 0.1106 - val_accuracy: 0.9693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-11-10 22:07:14,336]\u001b[0m Trial 37 finished with value: 0.9693121910095215 and parameters: {'num_conv_layers': 1, 'filters': 16, 'kernel_size': 3, 'strides': 2, 'activation': 'tanh', 'num_dense_layers': 2, 'units': 48, 'optimizer_name': 'RMRProp', 'learning_rate': 0.0037509134972159995, 'momentum': 0.4353231045088961}. Best is trial 36 with value: 0.9740740656852722.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.2617 - accuracy: 0.9202 - val_loss: 0.1620 - val_accuracy: 0.9495\n",
            "Epoch 2/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.1054 - accuracy: 0.9677 - val_loss: 0.1181 - val_accuracy: 0.9661\n",
            "Epoch 3/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.0775 - accuracy: 0.9768 - val_loss: 0.1040 - val_accuracy: 0.9701\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-11-10 22:07:20,176]\u001b[0m Trial 38 finished with value: 0.9701058268547058 and parameters: {'num_conv_layers': 1, 'filters': 16, 'kernel_size': 3, 'strides': 2, 'activation': 'tanh', 'num_dense_layers': 2, 'units': 40, 'optimizer_name': 'RMRProp', 'learning_rate': 0.0049101823182365004, 'momentum': 0.42197637730897386}. Best is trial 36 with value: 0.9740740656852722.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 0.2552 - accuracy: 0.9200 - val_loss: 0.1352 - val_accuracy: 0.9569\n",
            "Epoch 2/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.1021 - accuracy: 0.9685 - val_loss: 0.1099 - val_accuracy: 0.9680\n",
            "Epoch 3/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.0753 - accuracy: 0.9767 - val_loss: 0.1055 - val_accuracy: 0.9717\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-11-10 22:07:26,283]\u001b[0m Trial 39 finished with value: 0.9716930985450745 and parameters: {'num_conv_layers': 1, 'filters': 16, 'kernel_size': 3, 'strides': 2, 'activation': 'tanh', 'num_dense_layers': 2, 'units': 42, 'optimizer_name': 'RMRProp', 'learning_rate': 0.004974008184944838, 'momentum': 0.42347625966505686}. Best is trial 36 with value: 0.9740740656852722.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 0.2678 - accuracy: 0.9178 - val_loss: 0.1461 - val_accuracy: 0.9579\n",
            "Epoch 2/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.1065 - accuracy: 0.9665 - val_loss: 0.1211 - val_accuracy: 0.9664\n",
            "Epoch 3/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.0746 - accuracy: 0.9765 - val_loss: 0.1264 - val_accuracy: 0.9638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-11-10 22:07:32,119]\u001b[0m Trial 40 finished with value: 0.9637566208839417 and parameters: {'num_conv_layers': 1, 'filters': 16, 'kernel_size': 3, 'strides': 2, 'activation': 'tanh', 'num_dense_layers': 2, 'units': 41, 'optimizer_name': 'RMRProp', 'learning_rate': 0.005171111982228654, 'momentum': 0.2996668220390358}. Best is trial 36 with value: 0.9740740656852722.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.2543 - accuracy: 0.9207 - val_loss: 0.1549 - val_accuracy: 0.9532\n",
            "Epoch 2/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.1039 - accuracy: 0.9693 - val_loss: 0.1028 - val_accuracy: 0.9709\n",
            "Epoch 3/3\n",
            "266/266 [==============================] - 1s 6ms/step - loss: 0.0759 - accuracy: 0.9762 - val_loss: 0.1034 - val_accuracy: 0.9704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-11-10 22:07:37,910]\u001b[0m Trial 41 finished with value: 0.970370352268219 and parameters: {'num_conv_layers': 1, 'filters': 16, 'kernel_size': 3, 'strides': 2, 'activation': 'tanh', 'num_dense_layers': 2, 'units': 49, 'optimizer_name': 'RMRProp', 'learning_rate': 0.0058720343046826514, 'momentum': 0.43495111214055926}. Best is trial 36 with value: 0.9740740656852722.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.2401 - accuracy: 0.9249 - val_loss: 0.1444 - val_accuracy: 0.9590\n",
            "Epoch 2/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.1092 - accuracy: 0.9670 - val_loss: 0.1011 - val_accuracy: 0.9735\n",
            "Epoch 3/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.0764 - accuracy: 0.9764 - val_loss: 0.1235 - val_accuracy: 0.9683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-11-10 22:07:43,996]\u001b[0m Trial 42 finished with value: 0.9682539701461792 and parameters: {'num_conv_layers': 1, 'filters': 16, 'kernel_size': 3, 'strides': 2, 'activation': 'tanh', 'num_dense_layers': 2, 'units': 60, 'optimizer_name': 'RMRProp', 'learning_rate': 0.005708231958534165, 'momentum': 0.4399360290142979}. Best is trial 36 with value: 0.9740740656852722.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "266/266 [==============================] - 3s 7ms/step - loss: 0.2640 - accuracy: 0.9160 - val_loss: 0.1988 - val_accuracy: 0.9376\n",
            "Epoch 2/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.1087 - accuracy: 0.9668 - val_loss: 0.1255 - val_accuracy: 0.9648\n",
            "Epoch 3/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.0744 - accuracy: 0.9769 - val_loss: 0.1168 - val_accuracy: 0.9672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-11-10 22:07:50,580]\u001b[0m Trial 43 finished with value: 0.9671957492828369 and parameters: {'num_conv_layers': 1, 'filters': 16, 'kernel_size': 3, 'strides': 2, 'activation': 'tanh', 'num_dense_layers': 2, 'units': 83, 'optimizer_name': 'RMRProp', 'learning_rate': 0.005890516914829362, 'momentum': 0.3586779119712424}. Best is trial 36 with value: 0.9740740656852722.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 0.3769 - accuracy: 0.8882 - val_loss: 0.1795 - val_accuracy: 0.9444\n",
            "Epoch 2/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.1326 - accuracy: 0.9605 - val_loss: 0.1295 - val_accuracy: 0.9646\n",
            "Epoch 3/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.0915 - accuracy: 0.9728 - val_loss: 0.1399 - val_accuracy: 0.9635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-11-10 22:07:56,671]\u001b[0m Trial 44 finished with value: 0.9634920358657837 and parameters: {'num_conv_layers': 1, 'filters': 16, 'kernel_size': 3, 'strides': 2, 'activation': 'tanh', 'num_dense_layers': 2, 'units': 158, 'optimizer_name': 'RMRProp', 'learning_rate': 0.006193931539722546, 'momentum': 0.2698066688892512}. Best is trial 36 with value: 0.9740740656852722.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 0.2586 - accuracy: 0.9202 - val_loss: 0.1581 - val_accuracy: 0.9516\n",
            "Epoch 2/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.1069 - accuracy: 0.9675 - val_loss: 0.1312 - val_accuracy: 0.9614\n",
            "Epoch 3/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.0821 - accuracy: 0.9745 - val_loss: 0.1351 - val_accuracy: 0.9651\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-11-10 22:08:02,760]\u001b[0m Trial 45 finished with value: 0.9650793671607971 and parameters: {'num_conv_layers': 1, 'filters': 16, 'kernel_size': 3, 'strides': 2, 'activation': 'tanh', 'num_dense_layers': 2, 'units': 30, 'optimizer_name': 'RMRProp', 'learning_rate': 0.005018113405321988, 'momentum': 0.4651331316771104}. Best is trial 36 with value: 0.9740740656852722.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 0.3405 - accuracy: 0.8955 - val_loss: 0.1874 - val_accuracy: 0.9455\n",
            "Epoch 2/3\n",
            "266/266 [==============================] - 1s 6ms/step - loss: 0.1207 - accuracy: 0.9633 - val_loss: 0.1235 - val_accuracy: 0.9640\n",
            "Epoch 3/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.0889 - accuracy: 0.9725 - val_loss: 0.1267 - val_accuracy: 0.9677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-11-10 22:08:08,623]\u001b[0m Trial 46 finished with value: 0.9677248597145081 and parameters: {'num_conv_layers': 1, 'filters': 16, 'kernel_size': 3, 'strides': 2, 'activation': 'tanh', 'num_dense_layers': 2, 'units': 83, 'optimizer_name': 'RMRProp', 'learning_rate': 0.0077631221122942155, 'momentum': 0.4113637037258866}. Best is trial 36 with value: 0.9740740656852722.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 0.4218 - accuracy: 0.8747 - val_loss: 0.1700 - val_accuracy: 0.9503\n",
            "Epoch 2/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.1497 - accuracy: 0.9577 - val_loss: 0.1647 - val_accuracy: 0.9579\n",
            "Epoch 3/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.1173 - accuracy: 0.9678 - val_loss: 0.1365 - val_accuracy: 0.9616\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-11-10 22:08:14,872]\u001b[0m Trial 47 finished with value: 0.9616402387619019 and parameters: {'num_conv_layers': 1, 'filters': 16, 'kernel_size': 3, 'strides': 2, 'activation': 'tanh', 'num_dense_layers': 3, 'units': 132, 'optimizer_name': 'RMRProp', 'learning_rate': 0.004765927413522573, 'momentum': 0.6149413285262699}. Best is trial 36 with value: 0.9740740656852722.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.3852 - accuracy: 0.8853 - val_loss: 0.2081 - val_accuracy: 0.9415\n",
            "Epoch 2/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.1672 - accuracy: 0.9502 - val_loss: 0.1663 - val_accuracy: 0.9534\n",
            "Epoch 3/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.1387 - accuracy: 0.9591 - val_loss: 0.1729 - val_accuracy: 0.9519\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-11-10 22:08:20,980]\u001b[0m Trial 48 finished with value: 0.9518518447875977 and parameters: {'num_conv_layers': 1, 'filters': 16, 'kernel_size': 3, 'strides': 2, 'activation': 'tanh', 'num_dense_layers': 2, 'units': 11, 'optimizer_name': 'RMRProp', 'learning_rate': 0.009712275940567994, 'momentum': 0.3874316701859814}. Best is trial 36 with value: 0.9740740656852722.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.2832 - accuracy: 0.9122 - val_loss: 0.1520 - val_accuracy: 0.9569\n",
            "Epoch 2/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.1122 - accuracy: 0.9656 - val_loss: 0.1352 - val_accuracy: 0.9598\n",
            "Epoch 3/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.0818 - accuracy: 0.9744 - val_loss: 0.1209 - val_accuracy: 0.9664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-11-10 22:08:26,811]\u001b[0m Trial 49 finished with value: 0.9664021134376526 and parameters: {'num_conv_layers': 1, 'filters': 16, 'kernel_size': 3, 'strides': 2, 'activation': 'tanh', 'num_dense_layers': 2, 'units': 67, 'optimizer_name': 'RMRProp', 'learning_rate': 0.003804346824717854, 'momentum': 0.21264315137419484}. Best is trial 36 with value: 0.9740740656852722.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 0.3492 - accuracy: 0.8885 - val_loss: 0.1482 - val_accuracy: 0.9561\n",
            "Epoch 2/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.1404 - accuracy: 0.9604 - val_loss: 0.1632 - val_accuracy: 0.9571\n",
            "Epoch 3/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.1169 - accuracy: 0.9684 - val_loss: 0.1964 - val_accuracy: 0.9556\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-11-10 22:08:33,025]\u001b[0m Trial 50 finished with value: 0.9555555582046509 and parameters: {'num_conv_layers': 1, 'filters': 16, 'kernel_size': 3, 'strides': 2, 'activation': 'relu', 'num_dense_layers': 3, 'units': 127, 'optimizer_name': 'RMRProp', 'learning_rate': 0.007107781301421246, 'momentum': 0.5323898651047789}. Best is trial 36 with value: 0.9740740656852722.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 0.2434 - accuracy: 0.9265 - val_loss: 0.1305 - val_accuracy: 0.9648\n",
            "Epoch 2/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.1029 - accuracy: 0.9693 - val_loss: 0.1107 - val_accuracy: 0.9675\n",
            "Epoch 3/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.0738 - accuracy: 0.9767 - val_loss: 0.1333 - val_accuracy: 0.9577\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-11-10 22:08:38,964]\u001b[0m Trial 51 finished with value: 0.9576719403266907 and parameters: {'num_conv_layers': 1, 'filters': 16, 'kernel_size': 3, 'strides': 2, 'activation': 'tanh', 'num_dense_layers': 2, 'units': 49, 'optimizer_name': 'RMRProp', 'learning_rate': 0.0034689971688921456, 'momentum': 0.4376904485760799}. Best is trial 36 with value: 0.9740740656852722.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 0.2636 - accuracy: 0.9232 - val_loss: 0.1501 - val_accuracy: 0.9556\n",
            "Epoch 2/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.1106 - accuracy: 0.9660 - val_loss: 0.1281 - val_accuracy: 0.9659\n",
            "Epoch 3/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.0827 - accuracy: 0.9745 - val_loss: 0.1296 - val_accuracy: 0.9624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-11-10 22:08:45,106]\u001b[0m Trial 52 finished with value: 0.9624338746070862 and parameters: {'num_conv_layers': 1, 'filters': 16, 'kernel_size': 3, 'strides': 2, 'activation': 'tanh', 'num_dense_layers': 2, 'units': 27, 'optimizer_name': 'RMRProp', 'learning_rate': 0.0038725692690113377, 'momentum': 0.47263399105266113}. Best is trial 36 with value: 0.9740740656852722.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 0.2522 - accuracy: 0.9218 - val_loss: 0.1572 - val_accuracy: 0.9574\n",
            "Epoch 2/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.1044 - accuracy: 0.9680 - val_loss: 0.1230 - val_accuracy: 0.9653\n",
            "Epoch 3/3\n",
            "266/266 [==============================] - 1s 6ms/step - loss: 0.0744 - accuracy: 0.9773 - val_loss: 0.1088 - val_accuracy: 0.9701\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-11-10 22:08:51,198]\u001b[0m Trial 53 finished with value: 0.9701058268547058 and parameters: {'num_conv_layers': 1, 'filters': 16, 'kernel_size': 3, 'strides': 2, 'activation': 'tanh', 'num_dense_layers': 2, 'units': 79, 'optimizer_name': 'RMRProp', 'learning_rate': 0.004749540602979373, 'momentum': 0.3403936890815702}. Best is trial 36 with value: 0.9740740656852722.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 0.4099 - accuracy: 0.8889 - val_loss: 0.2269 - val_accuracy: 0.9341\n",
            "Epoch 2/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.1314 - accuracy: 0.9609 - val_loss: 0.1175 - val_accuracy: 0.9669\n",
            "Epoch 3/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.0943 - accuracy: 0.9723 - val_loss: 0.1214 - val_accuracy: 0.9690\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-11-10 22:08:57,195]\u001b[0m Trial 54 finished with value: 0.9690476059913635 and parameters: {'num_conv_layers': 1, 'filters': 16, 'kernel_size': 3, 'strides': 2, 'activation': 'tanh', 'num_dense_layers': 2, 'units': 193, 'optimizer_name': 'RMRProp', 'learning_rate': 0.005608223840162485, 'momentum': 0.3495341122191895}. Best is trial 36 with value: 0.9740740656852722.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.2780 - accuracy: 0.9139 - val_loss: 0.1527 - val_accuracy: 0.9553\n",
            "Epoch 2/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.1058 - accuracy: 0.9664 - val_loss: 0.1202 - val_accuracy: 0.9638\n",
            "Epoch 3/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.0693 - accuracy: 0.9775 - val_loss: 0.1047 - val_accuracy: 0.9685\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-11-10 22:09:02,974]\u001b[0m Trial 55 finished with value: 0.9685184955596924 and parameters: {'num_conv_layers': 1, 'filters': 16, 'kernel_size': 3, 'strides': 2, 'activation': 'tanh', 'num_dense_layers': 2, 'units': 80, 'optimizer_name': 'Adam', 'learning_rate': 0.004771527560163602}. Best is trial 36 with value: 0.9740740656852722.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "266/266 [==============================] - 3s 7ms/step - loss: 0.3083 - accuracy: 0.9059 - val_loss: 0.1582 - val_accuracy: 0.9526\n",
            "Epoch 2/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.1197 - accuracy: 0.9643 - val_loss: 0.1301 - val_accuracy: 0.9643\n",
            "Epoch 3/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.0810 - accuracy: 0.9750 - val_loss: 0.1090 - val_accuracy: 0.9680\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-11-10 22:09:09,433]\u001b[0m Trial 56 finished with value: 0.967989444732666 and parameters: {'num_conv_layers': 1, 'filters': 16, 'kernel_size': 3, 'strides': 2, 'activation': 'tanh', 'num_dense_layers': 2, 'units': 111, 'optimizer_name': 'RMRProp', 'learning_rate': 0.005989273640465403, 'momentum': 0.2692769141150309}. Best is trial 36 with value: 0.9740740656852722.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 0.4081 - accuracy: 0.8672 - val_loss: 0.1607 - val_accuracy: 0.9513\n",
            "Epoch 2/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.1306 - accuracy: 0.9594 - val_loss: 0.1356 - val_accuracy: 0.9614\n",
            "Epoch 3/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.0933 - accuracy: 0.9709 - val_loss: 0.1083 - val_accuracy: 0.9677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-11-10 22:09:15,509]\u001b[0m Trial 57 finished with value: 0.9677248597145081 and parameters: {'num_conv_layers': 1, 'filters': 16, 'kernel_size': 3, 'strides': 2, 'activation': 'relu', 'num_dense_layers': 2, 'units': 29, 'optimizer_name': 'RMRProp', 'learning_rate': 0.0047135187730374135, 'momentum': 0.12104569287186734}. Best is trial 36 with value: 0.9740740656852722.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 0.2506 - accuracy: 0.9214 - val_loss: 0.1884 - val_accuracy: 0.9413\n",
            "Epoch 2/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.1075 - accuracy: 0.9670 - val_loss: 0.1132 - val_accuracy: 0.9661\n",
            "Epoch 3/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.0749 - accuracy: 0.9774 - val_loss: 0.1087 - val_accuracy: 0.9717\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-11-10 22:09:21,606]\u001b[0m Trial 58 finished with value: 0.9716930985450745 and parameters: {'num_conv_layers': 1, 'filters': 16, 'kernel_size': 3, 'strides': 2, 'activation': 'tanh', 'num_dense_layers': 2, 'units': 65, 'optimizer_name': 'RMRProp', 'learning_rate': 0.005325738799483061, 'momentum': 0.48539559949670874}. Best is trial 36 with value: 0.9740740656852722.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.2770 - accuracy: 0.9158 - val_loss: 0.1417 - val_accuracy: 0.9595\n",
            "Epoch 2/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.0980 - accuracy: 0.9697 - val_loss: 0.1103 - val_accuracy: 0.9669\n",
            "Epoch 3/3\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 0.0660 - accuracy: 0.9792 - val_loss: 0.0902 - val_accuracy: 0.9738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-11-10 22:09:27,724]\u001b[0m Trial 59 finished with value: 0.973809540271759 and parameters: {'num_conv_layers': 2, 'filters': 16, 'kernel_size': 3, 'strides': 2, 'activation': 'tanh', 'num_dense_layers': 2, 'units': 61, 'optimizer_name': 'Adam', 'learning_rate': 0.005330910713807278}. Best is trial 36 with value: 0.9740740656852722.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wq4Qbncm4fTl",
        "outputId": "85c2e2cf-0957-4859-da24-42a73fa0a51e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "study.best_params\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': 'tanh',\n",
              " 'filters': 16,\n",
              " 'kernel_size': 3,\n",
              " 'learning_rate': 0.002878983904416791,\n",
              " 'momentum': 0.4781051050947992,\n",
              " 'num_conv_layers': 1,\n",
              " 'num_dense_layers': 2,\n",
              " 'optimizer_name': 'RMRProp',\n",
              " 'strides': 2,\n",
              " 'units': 42}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9h_pZQw4i-L",
        "outputId": "f925f5d1-357d-42de-9bf4-7cc3d55c0d43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "study.best_value"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9740740656852722"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAAsLEVm1DZz",
        "outputId": "7295f2c6-4d84-4dbd-febc-b83d9bb46348",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "#analyze result\n",
        "\n",
        "\n",
        "results = study.trials_dataframe()\n",
        "\n",
        "results['value'].sort_values().reset_index(drop=True).plot()\n",
        "plt.title('convergence plot')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Accuracy')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Esa4KhCV1mPP",
        "outputId": "bf4c4ae1-1edc-499e-9361-fd10342f8aa0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Evaluate\n",
        "model = load_model(path_best_model)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_36\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_36 (Conv2D)          (None, 14, 14, 16)        160       \n",
            "                                                                 \n",
            " max_pooling2d_36 (MaxPoolin  (None, 7, 7, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_36 (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " dense_95 (Dense)            (None, 42)                32970     \n",
            "                                                                 \n",
            " dense_96 (Dense)            (None, 42)                1806      \n",
            "                                                                 \n",
            " dense_97 (Dense)            (None, 10)                430       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 35,366\n",
            "Trainable params: 35,366\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dyiu3UD85wOq",
        "outputId": "6b6197c9-5005-4f8a-c83f-fbe14dd714df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "results = model.evaluate(x=X_test, y = y_test)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0870 - accuracy: 0.9745\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrbeTIaN57OF",
        "outputId": "62e137c2-e18a-48c9-a4b8-f128a16e177e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for name , value in zip(model.metrics_names,results):\n",
        "  print(name, value)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.08697552233934402\n",
            "accuracy 0.9745237827301025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzhKN-x75_vZ",
        "outputId": "b57fd35f-b6f7-48f2-e109-2671870460a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#confuison matrix\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes= np.argmax(y_pred, axis=1)\n",
        "y_true= np.argmax(y_test, axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred_classes)\n",
        "\n",
        "cm\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[413,   0,   1,   1,   0,   0,   4,   0,   2,   1],\n",
              "       [  0, 470,   3,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  1,   2, 401,   1,   0,   1,   1,   2,   0,   0],\n",
              "       [  0,   0,   3, 408,   0,   4,   1,   5,   3,   2],\n",
              "       [  1,   2,   1,   0, 422,   0,   2,   0,   0,   1],\n",
              "       [  0,   0,   0,   3,   0, 371,   3,   0,   3,   2],\n",
              "       [  0,   1,   2,   0,   1,   2, 406,   0,   0,   0],\n",
              "       [  0,   3,   5,   2,   1,   0,   0, 458,   0,   0],\n",
              "       [  0,   1,   3,   2,   0,   3,   3,   1, 370,   1],\n",
              "       [  2,   1,   0,   3,  10,   1,   0,   3,   0, 374]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrjeZpnh6nF2",
        "outputId": "0f200ed5-c32f-4126-9a23-c5dcf7594c38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "source": [
        "# let's make it more colourful\n",
        "classes = 10\n",
        "\n",
        "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title('Confusion matrix')\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(classes)\n",
        "plt.xticks(tick_marks, range(classes), rotation=45)\n",
        "plt.yticks(tick_marks, range(classes))\n",
        "\n",
        "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    plt.text(j, i, cm[i, j],\n",
        "             horizontalalignment=\"center\",\n",
        "             color=\"white\" if cm[i, j] > 100 else \"black\",\n",
        "            )\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 13.421126458070283, 'Predicted label')"
            ]
          },
          "metadata": {},
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}